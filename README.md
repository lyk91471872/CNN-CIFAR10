# CNN-CIFAR10

A PyTorch implementation of Convolutional Neural Networks for the CIFAR-10 dataset. This project provides a flexible and modular framework for training, evaluating, and deploying CNN models on the CIFAR-10 image classification task.

## About
This repo is the codebase for the first group project of NYU CS-GY-6953 Deep Learning, 2025 Spring. For the code under Setting 2 mentioned in the report, please check this [link](https://github.com/Hadlay-Zhang/ResNet-cifar).

### Team Members
Yukang Luo, Zhilin Zhang, Yumeng Qian.

### Submission
Our final Kaggle submission CSV is generated by *custom-resnet.ipynb*, a standalone notebook created and executed on [Kaggle](https://www.kaggle.com/code/yukangluo/custom-resnet). A copy of the notebook is included in this repository. The rest of the codebase reflects the various strategies we experimented with.

## Features

- **Multiple Custom CNN Architectures <5M Parameters**
  - CustomResNet18 - ResNet18 with manually set channel depths
  - CustomResNet18X - ResNet18 with doubling channel depths [X, 2X, 4X, 8X] (largest X=42 for <5M)
  - PreActResNet18 - ResNet18 with pre-activation blocks (BN→ReLU→CONV ordering) (X=42)
  - EfficientNetV2-B0 - EfficientNet with compound scaling, modified to <5M
  - CustomResNet34 - Attempted as the teacher model (>5M) for distillation, no visible improvement

- **Advanced Training Capabilities**
  - Cross-validation support with averaged metrics visualization
  - Early stopping to prevent overfitting
  - Learning rate scheduling with ReduceLROnPlateau, CosineAnnealingLR
  - Learning rate warmup for improved stability
  - Mixup and cutmix implementation for better generalization

- **Data Management**
  - Efficient data loading with optimized DataLoader
  - Comprehensive data augmentation pipeline with AutoAugment
  - Grid search for optimal data augmentation combinations (incomplete due to computational cost)
  - Training set visualization with PDF export

- **Experiment Tracking**
  - Session-based tracking with JSON files
  - Standardized naming scheme for all artifacts
  - Detailed metrics tracking across training runs
  - Confusion matrix visualization for error analysis
  - Training history and cross-validation visualization

- **Utility Scripts**
  - DataLoader benchmarking for performance optimization
  - Test and training set visualization with PDF export
  - Grid search for optimal data augmentation strategies
  - Channel size optimization for CustomResNet18X
  - Normalization value computation and config updates

## Project Structure

```
CNN-CIFAR10/
├── __init__.py             # Root package initialization
├── config.py               # Global configuration settings
├── custom-resnet.ipynb     # Standalone notebook
├── dataset.py              # Dataset classes for CIFAR-10
├── main.py                 # Main script with CLI commands
├── models/                 # Model definitions
│   ├── __init__.py         # Models package initialization
│   ├── base.py             # Base model class with save/load functionality
│   ├── preact_resnet.py    # Pre-activation ResNet-18 implementation
│   ├── resnet.py           # ResNet-18 and variants
│   └── efficientnet.py     # EfficientNetV2-B0 implementation
├── scripts/                # Utility scripts
│   ├── __init__.py         # Scripts package initialization
│   ├── dataloader_benchmark.py         # Benchmark dataloader performance
│   ├── grid_search_augmentation.py     # Find optimal data augmentation
│   ├── search_channel_size.py          # Optimize ResNet18X channel width
│   ├── testset2pdf.py                  # Export test set images to PDF
│   ├── trainingset2pdf.py              # Export training set images to PDF
│   ├── outputs/                        # Directory for script outputs
│   └── update_normalization_values.py  # Update normalization values in config
├── utils/                  # Utility modules
│   ├── __init__.py         # Utils package initialization
│   ├── augmentation.py     # Data augmentation utilities
│   ├── early_stopping.py   # Early stopping implementation
│   ├── pipeline.py         # Training and evaluation pipeline
│   ├── session.py          # Session tracking with JSON
│   └── visualization.py    # Visualization tools (history, confusion matrices)
├── weights/                # Model weights storage
├── graphs/                 # Training graphs output
├── results/                # Central location for all results
├── tracking/               # JSON tracking files
└── predictions/            # Model predictions storage
```

## Installation

### Prerequisites

- Python 3.6+
- PyTorch 1.7+
- CUDA-capable GPU (recommended)

### Setup

1. Clone the repository:
```bash
git clone git@github.com:lyk91471872/CNN-CIFAR10.git
cd CNN-CIFAR10
```

2. Install the package in development mode:
```bash
pip install -e .
```

This will automatically install all dependencies from `requirements.txt`.

## Usage

### Command-Line Interface

The project now uses a unified Click-based CLI in main.py with multiple commands and aliases:

| Command (Alias) | Description |
|-----------------|-------------|
| `train` (`t`) | Train model on full dataset |
| `crossval` (`c`) | Run cross-validation |
| `grid-search` (`g`) | Run grid search for optimal data augmentation |
| `search-channels` (`s`) | Find optimal channel size for CustomResNet18X |
| `pdf` (`p`) | Generate PDF of test images |
| `train-pdf` (`tp`) | Generate PDF of training images |
| `benchmark` (`b`) | Run dataloader benchmark |
| `normalize` (`n`) | Update normalization values |
| `list-sessions` (`l`) | List recent training/cross-validation sessions |

### Training a Model

To train a model on the full dataset:

```bash
python main.py train
# Or using the alias
python main.py t
```

This will:
- Load the CIFAR-10 dataset
- Initialize the model specified in `config.py`
- Train the model with learning rate warmup
- Save the best model weights using the session-based naming scheme
- Generate visualization of training history and confusion matrix
- Create a prediction file for test data
- Track the session in a JSON file

### Cross-validation

To run cross-validation:

```bash
python main.py crossval
# Or using the alias
python main.py c
```

This will:
- Split the dataset into k folds (default: 5)
- Train and evaluate the model on each fold
- Report the average performance across all folds
- Generate an averaged training history plot
- Plot confusion matrices for each fold and the average
- Save the session data to a JSON file

### Finding Optimal Data Augmentation

To run a grid search for the best data augmentation strategy:

```bash
python main.py grid-search [epochs]
# Or using the alias
python main.py g [epochs]
```

This will:
- Train models with different combinations of augmentation techniques
- Each model is trained for a fixed number of epochs for fair comparison
- Generate a CSV file with results of all combinations
- Print the top-performing augmentation strategies
- Recommend the best configuration for your config.py

### Generating PDFs of Images

To generate PDF visualizations of datasets:

```bash
# For test images
python main.py pdf
# Or using the alias
python main.py p

# For training images
python main.py train-pdf
# Or using the alias
python main.py tp
```

### Listing Recent Sessions

To list recent training or cross-validation sessions:

```bash
python main.py list-sessions [--model MODEL] [--type TYPE] [--limit LIMIT]
# Or using the alias
python main.py l [--model MODEL] [--type TYPE] [--limit LIMIT]
```

This will display recent sessions with their:
- Model name
- Session type (training or crossval)
- Timestamp
- Accuracy metrics
- File paths for weights, plots, etc.

## Configuration

All configuration options are centralized in `config.py`, including:

- Model selection via `get_model()` function
- DataLoader parameters
- Optimizer settings (learning rate, weight decay, momentum)
- Learning rate scheduler parameters
- Data augmentation transforms
- Normalization values
- Training parameters (epochs, early stopping, warmup)
- Directory paths

## Session Tracking

The project uses a JSON-based system for tracking experiments:

1. **Session-based Organization**
   - Each training or cross-validation run creates a session
   - Standard naming scheme for all artifacts
   - Files stored in appropriate directories (weights, graphs, predictions)

2. **SessionTracker Features**
   - Records model configuration
   - Tracks hyperparameters
   - Stores performance metrics
   - Maintains references to all generated files
   - Facilitates browsing previous sessions

3. **Session Naming Convention**
   - Format: `{model}_E{epoch}_A{accuracy}_{timestamp}`
   - Consistent across weights, graphs, and predictions
   - Easy to correlate artifacts from the same run

## License

This project is licensed under the MIT License - see the LICENSE file for details.
